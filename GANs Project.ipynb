{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["from __future__ import print_function\n","import argparse\n","import os\n","import random\n","import torch\n","import torch.nn as nn\n","import torch.nn.parallel\n","import torch.backends.cudnn as cudnn\n","import torch.optim as optim\n","import torch.utils.data\n","import torchvision.datasets as dset\n","import torchvision.transforms as transforms\n","import torchvision.utils as vutils\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.animation as animation\n","from IPython.display import HTML\n","from torchvision.utils import save_image\n","from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","seed_everything()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["len(os.listdir('../input/all-dogs/all-dogs'))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataroot = \"../input/all-dogs\"\n","workers = 2\n","\n","batch_size = 128\n","image_size = 64\n","\n","nc = 3\n","nz = 100\n","ngf = 64\n","ndf = 64\n","\n","num_epochs = 30\n","lr = 0.0001\n","beta1 = 0.3\n","ngpu = 1"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["dataset = dset.ImageFolder(root=dataroot,\n","                           transform=transforms.Compose([\n","                               transforms.Resize(image_size),\n","                               transforms.RandomHorizontalFlip(),\n","                               transforms.CenterCrop(image_size),\n","                               transforms.ToTensor(),\n","                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","                           ]))\n","dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,shuffle=True, num_workers=workers)\n","\n","device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["real_batch = next(iter(dataloader))\n","plt.figure(figsize=(10,10))\n","plt.axis(\"off\")\n","plt.title(\"Training Images\");\n","plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)));"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def weights_init(m):\n","    classname = m.__class__.__name__\n","    if classname.find('Conv') != -1:\n","        nn.init.normal_(m.weight.data, 0.0, 0.02)\n","    elif classname.find('BatchNorm') != -1:\n","        nn.init.normal_(m.weight.data, 1.0, 0.02)\n","        nn.init.constant_(m.bias.data, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class Generator(nn.Module):\n","    def __init__(self, ngpu):\n","        super(Generator, self).__init__()\n","        self.ngpu = ngpu\n","        self.main = nn.Sequential(\n","            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n","            nn.BatchNorm2d(ngf * 8),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 4),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf * 2),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ngf),\n","            nn.ReLU(True),\n","            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n","            nn.Tanh()\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)\n","    \n","\n","netG = Generator(ngpu).to(device);\n","netG.apply(weights_init)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["class Discriminator(nn.Module):\n","    def __init__(self, ngpu):\n","        super(Discriminator, self).__init__()\n","        self.ngpu = ngpu\n","        self.main = nn.Sequential(\n","            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 2),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 4),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n","            nn.BatchNorm2d(ndf * 8),\n","            nn.LeakyReLU(0.2, inplace=True),\n","            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, input):\n","        return self.main(input)\n","    \n","netD = Discriminator(ngpu).to(device);\n","netD.apply(weights_init);"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["criterion = nn.BCELoss()\n","\n","fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n","\n","real_label = 1\n","fake_label = 0\n","\n","optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n","optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n","scheduler = ReduceLROnPlateau(optimizerD, factor=0.5, patience=2)\n","scheduler = StepLR(optimizerD, gamma=0.5, step_size=8)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["G_losses = []\n","D_losses = []\n","iters = 0\n","\n","valid_loss_min = np.Inf\n","patience = 5\n","p = 0\n","stop = False\n","\n","\n","print(\"Starting Training Loop...\")\n","for epoch in range(num_epochs):\n","    for i, data in enumerate(dataloader, 0):\n","\n","        netD.zero_grad()\n","        real_cpu = data[0].to(device)\n","        b_size = real_cpu.size(0)\n","        label = torch.full((b_size,), real_label, device=device)\n","        output = netD(real_cpu).view(-1)\n","        errD_real = criterion(output, label)\n","        errD_real.backward()\n","        D_x = output.mean().item()\n","\n","        noise = torch.randn(b_size, nz, 1, 1, device=device)\n","        fake = netG(noise)\n","        label.fill_(fake_label)\n","        output = netD(fake.detach()).view(-1)\n","        errD_fake = criterion(output, label)\n","        errD_fake.backward()\n","        D_G_z1 = output.mean().item()\n","        errD = errD_real + errD_fake\n","        optimizerD.step()\n","\n","        netG.zero_grad()\n","        label.fill_(real_label)  \n","        output = netD(fake).view(-1)\n","        errG = criterion(output, label)\n","        errG.backward()\n","        D_G_z2 = output.mean().item()\n","        optimizerG.step()\n","\n","        G_losses.append(errG.item())\n","        D_losses.append(errD.item())\n","\n","        iters += 1\n","    scheduler.step(errD.item())\n","    \n","    print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n","          % (epoch, num_epochs, i, len(dataloader),\n","             errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n","  "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(10,5))\n","plt.title(\"Generator and Discriminator Loss During Training\")\n","plt.plot(G_losses,label=\"G\")\n","plt.plot(D_losses,label=\"D\")\n","plt.xlabel(\"iterations\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["if not os.path.exists('../output_images'):\n","    os.mkdir('../output_images')\n","im_batch_size = 50\n","n_images=10000\n","for i_batch in range(0, n_images, im_batch_size):\n","    gen_z = torch.randn(im_batch_size, nz, 1, 1, device=device)\n","    gen_images = netG(gen_z)\n","    images = gen_images.to(\"cpu\").clone().detach()\n","    images = images.numpy().transpose(0, 2, 3, 1)\n","    for i_image in range(gen_images.size(0)):\n","        save_image(gen_images[i_image, :, :, :], os.path.join('../output_images', f'image_{i_batch+i_image:05d}.png'))\n","\n","\n","import shutil\n","shutil.make_archive('images', 'zip', '../output_images')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig = plt.figure(figsize=(25, 16))\n","for i, j in enumerate(images[:32]):\n","    ax = fig.add_subplot(4, 8, i + 1, xticks=[], yticks=[])\n","    plt.imshow(j)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":545987,"sourceId":15062,"sourceType":"competition"}],"dockerImageVersionId":28450,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
